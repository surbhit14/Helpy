
![image](https://user-images.githubusercontent.com/82264758/151252015-243d74f8-401f-45b4-a165-c16d81717a56.png)

# Helpy
Helpy is a platform that helps deaf and mute people to express their views and points to other people in a meeting in a much better way.
Mute people can quickly draw shapes and other text to explain what they are trying to say and similarly this can be used to explain something to deaf people more efficiently.It has various functionalities like drawing shapes,text and free draw on video.
It also has sign language recognition feature which converts sign language and displays text on screen/video.

![image](https://user-images.githubusercontent.com/82264758/151252075-512d0e2e-8ad1-4428-9f5d-459e27cda574.png)

![image](https://user-images.githubusercontent.com/82264758/151252216-cf7a93c2-ea4c-4660-8098-a103a6b4df14.png)


Google Drive Video Link: https://drive.google.com/file/d/1Kh-ZkrQMj_RBniMOypFCxEmym2IrAa_P/view?usp=sharing

Challenges I ran into
Some of the challenges I ran into were
1.Handling multiple conditions in openCV
2.Rendering different types of images
3.Drawing shapes and text on screen
4.Designing the UI in openCV
5.Hand and finger detection using openCV
